{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4c1dc95-69d8-4801-836c-c780b34b4059",
   "metadata": {},
   "source": [
    "## OPT:\n",
    "  From : https://www.pragnakalp.com/exploring-the-text-generation-with-opt-open-pre-trained-transformers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "254aa5fa-8065-4b57-a6ce-a0ba5f8bb676",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#import sys\n",
    "from transformers import AutoTokenizer, GPT2Tokenizer\n",
    "from megatron.initialize import initialize_megatron\n",
    "#sys.path.insert(0, './metaseq')\n",
    "from metaseq import checkpoint_utils\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad21cf90-fc2c-4efd-bad1-92a966d0c527",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--num-layers NUM_LAYERS]\n",
      "                             [--hidden-size HIDDEN_SIZE]\n",
      "                             [--ffn-hidden-size FFN_HIDDEN_SIZE]\n",
      "                             [--num-attention-heads NUM_ATTENTION_HEADS]\n",
      "                             [--kv-channels KV_CHANNELS]\n",
      "                             [--max-position-embeddings MAX_POSITION_EMBEDDINGS]\n",
      "                             [--make-vocab-size-divisible-by MAKE_VOCAB_SIZE_DIVISIBLE_BY]\n",
      "                             [--layernorm-epsilon LAYERNORM_EPSILON]\n",
      "                             [--apply-residual-connection-post-layernorm]\n",
      "                             [--openai-gelu] [--onnx-safe ONNX_SAFE]\n",
      "                             [--bert-no-binary-head]\n",
      "                             [--attention-dropout ATTENTION_DROPOUT]\n",
      "                             [--hidden-dropout HIDDEN_DROPOUT]\n",
      "                             [--weight-decay WEIGHT_DECAY]\n",
      "                             [--clip-grad CLIP_GRAD] [--adam-beta1 ADAM_BETA1]\n",
      "                             [--adam-beta2 ADAM_BETA2] [--adam-eps ADAM_EPS]\n",
      "                             [--sgd-momentum SGD_MOMENTUM]\n",
      "                             [--micro-batch-size MICRO_BATCH_SIZE]\n",
      "                             [--batch-size BATCH_SIZE]\n",
      "                             [--global-batch-size GLOBAL_BATCH_SIZE]\n",
      "                             [--rampup-batch-size [RAMPUP_BATCH_SIZE ...]]\n",
      "                             [--checkpoint-activations]\n",
      "                             [--distribute-checkpointed-activations]\n",
      "                             [--activations-checkpoint-method {uniform,block}]\n",
      "                             [--activations-checkpoint-num-layers ACTIVATIONS_CHECKPOINT_NUM_LAYERS]\n",
      "                             [--train-iters TRAIN_ITERS]\n",
      "                             [--train-samples TRAIN_SAMPLES]\n",
      "                             [--log-interval LOG_INTERVAL]\n",
      "                             [--exit-interval EXIT_INTERVAL]\n",
      "                             [--exit-duration-in-mins EXIT_DURATION_IN_MINS]\n",
      "                             [--tensorboard-dir TENSORBOARD_DIR]\n",
      "                             [--no-masked-softmax-fusion]\n",
      "                             [--no-bias-gelu-fusion]\n",
      "                             [--no-bias-dropout-fusion]\n",
      "                             [--optimizer {adam,sgd}]\n",
      "                             [--dataloader-type {single,cyclic}]\n",
      "                             [--no-async-tensor-model-parallel-allreduce]\n",
      "                             [--seed SEED] [--init-method-std INIT_METHOD_STD]\n",
      "                             [--init-method-xavier-uniform] [--lr LR]\n",
      "                             [--lr-decay-style {constant,linear,cosine}]\n",
      "                             [--lr-decay-iters LR_DECAY_ITERS]\n",
      "                             [--lr-decay-samples LR_DECAY_SAMPLES]\n",
      "                             [--lr-warmup-fraction LR_WARMUP_FRACTION]\n",
      "                             [--lr-warmup-iters LR_WARMUP_ITERS]\n",
      "                             [--lr-warmup-samples LR_WARMUP_SAMPLES]\n",
      "                             [--warmup WARMUP] [--min-lr MIN_LR]\n",
      "                             [--override-lr-scheduler]\n",
      "                             [--use-checkpoint-lr-scheduler] [--save SAVE]\n",
      "                             [--save-interval SAVE_INTERVAL] [--no-save-optim]\n",
      "                             [--no-save-rng] [--load LOAD] [--no-load-optim]\n",
      "                             [--no-load-rng] [--finetune] [--fp16] [--bf16]\n",
      "                             [--loss-scale LOSS_SCALE]\n",
      "                             [--initial-loss-scale INITIAL_LOSS_SCALE]\n",
      "                             [--min-loss-scale MIN_LOSS_SCALE]\n",
      "                             [--loss-scale-window LOSS_SCALE_WINDOW]\n",
      "                             [--hysteresis HYSTERESIS]\n",
      "                             [--fp32-residual-connection]\n",
      "                             [--no-query-key-layer-scaling]\n",
      "                             [--attention-softmax-in-fp32]\n",
      "                             [--accumulate-allreduce-grads-in-fp32]\n",
      "                             [--fp16-lm-cross-entropy]\n",
      "                             [--tensor-model-parallel-size TENSOR_MODEL_PARALLEL_SIZE]\n",
      "                             [--pipeline-model-parallel-size PIPELINE_MODEL_PARALLEL_SIZE]\n",
      "                             [--pipeline-model-parallel-split-rank PIPELINE_MODEL_PARALLEL_SPLIT_RANK]\n",
      "                             [--model-parallel-size MODEL_PARALLEL_SIZE]\n",
      "                             [--num-layers-per-virtual-pipeline-stage NUM_LAYERS_PER_VIRTUAL_PIPELINE_STAGE]\n",
      "                             [--distributed-backend {nccl,gloo}]\n",
      "                             [--DDP-impl {local,torch}]\n",
      "                             [--no-contiguous-buffers-in-local-ddp]\n",
      "                             [--no-scatter-gather-tensors-in-pipeline]\n",
      "                             [--local_rank LOCAL_RANK]\n",
      "                             [--lazy-mpu-init LAZY_MPU_INIT]\n",
      "                             [--use-cpu-initialization]\n",
      "                             [--empty-unused-memory-level {0,1,2}]\n",
      "                             [--eval-iters EVAL_ITERS]\n",
      "                             [--eval-interval EVAL_INTERVAL]\n",
      "                             [--data-path [DATA_PATH ...]] [--split SPLIT]\n",
      "                             [--vocab-file VOCAB_FILE]\n",
      "                             [--merge-file MERGE_FILE]\n",
      "                             [--vocab-extra-ids VOCAB_EXTRA_IDS]\n",
      "                             [--seq-length SEQ_LENGTH]\n",
      "                             [--encoder-seq-length ENCODER_SEQ_LENGTH]\n",
      "                             [--decoder-seq-length DECODER_SEQ_LENGTH]\n",
      "                             [--retriever-seq-length RETRIEVER_SEQ_LENGTH]\n",
      "                             [--sample-rate SAMPLE_RATE]\n",
      "                             [--mask-prob MASK_PROB]\n",
      "                             [--short-seq-prob SHORT_SEQ_PROB] [--mmap-warmup]\n",
      "                             [--num-workers NUM_WORKERS]\n",
      "                             [--tokenizer-type {BertWordPieceLowerCase,BertWordPieceCase,GPT2BPETokenizer}]\n",
      "                             [--data-impl {lazy,cached,mmap,infer}]\n",
      "                             [--reset-position-ids] [--reset-attention-mask]\n",
      "                             [--eod-mask-loss] [--adlr-autoresume]\n",
      "                             [--adlr-autoresume-interval ADLR_AUTORESUME_INTERVAL]\n",
      "                             [--ict-head-size ICT_HEAD_SIZE]\n",
      "                             [--biencoder-projection-dim BIENCODER_PROJECTION_DIM]\n",
      "                             [--biencoder-shared-query-context-model]\n",
      "                             [--ict-load ICT_LOAD] [--bert-load BERT_LOAD]\n",
      "                             [--titles-data-path TITLES_DATA_PATH]\n",
      "                             [--query-in-block-prob QUERY_IN_BLOCK_PROB]\n",
      "                             [--use-one-sent-docs]\n",
      "                             [--evidence-data-path EVIDENCE_DATA_PATH]\n",
      "                             [--retriever-report-topk-accuracies RETRIEVER_REPORT_TOPK_ACCURACIES [RETRIEVER_REPORT_TOPK_ACCURACIES ...]]\n",
      "                             [--retriever-score-scaling]\n",
      "                             [--block-data-path BLOCK_DATA_PATH]\n",
      "                             [--embedding-path EMBEDDING_PATH]\n",
      "                             [--indexer-batch-size INDEXER_BATCH_SIZE]\n",
      "                             [--indexer-log-interval INDEXER_LOG_INTERVAL]\n",
      "                             [--num-classes NUM_CLASSES] [--img-dim IMG_DIM]\n",
      "                             [--num-channels NUM_CHANNELS]\n",
      "                             [--patch-dim PATCH_DIM] [--log-params-norm]\n",
      "                             [--log-num-zeros-in-grad]\n",
      "                             [--tensorboard-log-interval TENSORBOARD_LOG_INTERVAL]\n",
      "                             [--tensorboard-queue-size TENSORBOARD_QUEUE_SIZE]\n",
      "                             [--log-timers-to-tensorboard]\n",
      "                             [--log-batch-size-to-tensorboard]\n",
      "                             [--no-log-learnig-rate-to-tensorboard]\n",
      "                             [--no-log-loss-scale-to-tensorboard]\n",
      "                             [--log-validation-ppl-to-tensorboard]\n",
      "                             [--log-memory-to-tensorboard]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/kevinchin/Library/Jupyter/runtime/kernel-aa4db71e-0370-4b14-81f8-ca58db3df7e7.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinchin/anaconda3/envs/hugface/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3513: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/kevinchin/Documents/python/hugface/opt/Megatron-LM/opt_metaseq_350m/model\"\n",
    "metaseq_path = \"/Users/kevinchin/Documents/python/hugface/opt/Megatron-LM/metaseq/metaseq\"\n",
    "\n",
    "# arguments taken from: https://arxiv.org/pdf/2205.01068.pdf | table 1\n",
    "initialize_megatron(args_defaults={\n",
    "    \"micro_batch_size\": 1, \n",
    "    \"num_layers\": 24, \n",
    "    \"hidden_size\": 1024, \n",
    "    \"num_attention_heads\": 16,\n",
    "    \"max_position_embeddings\": 2048, # TODO check if it is the correct args\n",
    "    \"encoder_seq_length\": 2048 # TODO check if it is the correct args\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475f6ef2-2772-4e6f-bd01-e63c6a07a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"facebook/bart-large\")\n",
    "tokenizer.save_pretrained(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c426e137-b0a0-4d60-92b4-d66ede882451",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = checkpoint_utils.load_model_ensemble_and_task(\n",
    "    [os.path.join(path, \"reshard.pt\")],\n",
    "#    [os.path.join(path, \"reshard-model_part-0.pt\"), os.path.join(path, \"reshard-model_part-1.pt\")],\n",
    "    arg_overrides={\n",
    "        \"vocab_filename\": os.path.join(path, \"vocab.json\"),\n",
    "        \"merges_filename\": os.path.join(path, \"merges.txt\"),\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
